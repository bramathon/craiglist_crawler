{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will model the data using a Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from data_utils import load_dataset, core_metrics,map_model\n",
    "\n",
    "plotly.io.templates.default = 'plotly_dark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lgbm api\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train,free_raw_data=False)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "params = {'objective':'regression','metric':'mae','learning_rate': 0.05, 'num_leaves': 301, \"max_depth\": 30, \"lambda_l2\": 0.03}\n",
    "evals_result = {}\n",
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=200,\n",
    "                  valid_sets=[train_data,test_data],\n",
    "                  valid_names=['Train','Test'],\n",
    "                  verbose_eval=20,\n",
    "                  evals_result=evals_result,\n",
    "                  )\n",
    "\n",
    "lgb.plot_metric(evals_result)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing but with sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "lg = lgb.LGBMRegressor(num_leaves=192,learning_rate=0.05,n_estimators=200,objective='l2',silent=False)\n",
    "\n",
    "param_dist = {'num_leaves': [31,51,101,151,201,301],\n",
    "              'max_depth': [10,20,30,-1],\n",
    "              'lambda_l2': [0.01,0.03,0.1,0.3]\n",
    "             }\n",
    "\n",
    "# if scoring is not provided, the estimator's scoring paramter is used\n",
    "cv = RandomizedSearchCV(lg,param_dist,n_iter=25,scoring='neg_median_absolute_error')\n",
    "\n",
    "search = cv.fit(X_train,y_train)\n",
    "\n",
    "best_params = search.best_params_\n",
    "\n",
    "lg.set_params(**best_params)\n",
    "\n",
    "lg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lg.predict(X_test)\n",
    "\n",
    "print(\"Best Params: {}\".format(best_params))\n",
    "metrics.mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import core_metrics\n",
    "\n",
    "core_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import mapbox_access_token\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# cache the populated coordinates\n",
    "\n",
    "populated_coordinates = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_coords (X_test,coordinates,lat_step,long_step):\n",
    "    global populated_coordinates\n",
    "    # removes coordinates which have no data\n",
    "    if populated_coordinates.any():\n",
    "        print('Using cached coordinates')\n",
    "        use_coordinates = np.array(populated_coordinates)\n",
    "    else:\n",
    "        populated_coordinates = []\n",
    "        for lat,long in coordinates:\n",
    "            if ((X_test['latitude'].between(lat,lat+lat_step)) & (X_test['longitude'].between(long,long + long_step))).any():\n",
    "                populated_coordinates.append([lat,long])\n",
    "        use_coordinates = np.array(populated_coordinates)\n",
    "        populated_coordinates = use_coordinates # set cache\n",
    "    return use_coordinates\n",
    "    \n",
    "\n",
    "def map_model (X_test,model):\n",
    "    # model should take X_test as an arugment to it's predict function\n",
    "    # we are going to map the price for the typical apartment around the whole city\n",
    "    \n",
    "    # typical apartment characteristics\n",
    "    date = X_test['date'].median()\n",
    "    area = X_test['area'].median()\n",
    "    bedrooms = X_test['bedrooms'].mode()[0]\n",
    "    pets = X_test['pets'].mode()[0]\n",
    "    furnished = X_test['furnished'].mode()[0]\n",
    "    unit_type = X_test['unit_type'].mode()[0]\n",
    "    \n",
    "    # construct a square grid\n",
    "    # throw away any points that are not close to real values\n",
    "    lats, lat_step = np.linspace(X_test['latitude'].min(),X_test['latitude'].max(),num=300,retstep=True)\n",
    "    longs, long_step = np.linspace(X_test['longitude'].min(),X_test['longitude'].max(),num=300,retstep=True)\n",
    "    coordinate_list = np.array(np.meshgrid(lats,longs)).T.reshape(-1,2)\n",
    "    \n",
    "    # can this be vectorized?\n",
    "    # now, remove the rows that aren't near real data\n",
    "    # to do this, set a threshold value for how close we need to find a point\n",
    "    # for each point in the dataframe, see if there is a point close enough\n",
    "    use_coordinates = remove_empty_coords(X_test,coordinate_list,lat_step,long_step)\n",
    "\n",
    "    df = pd.DataFrame(use_coordinates,columns=['latitude','longitude'])\n",
    "    df.loc[:,'date'] = date\n",
    "    df.loc[:,'area'] = area\n",
    "    df.loc[:,'bedrooms'] = bedrooms\n",
    "    df.loc[:,'pets'] = pets\n",
    "    df.loc[:,'furnished'] = furnished\n",
    "    df.loc[:,'unit_type'] = unit_type\n",
    "    df['unit_type'] = pd.Categorical(df['unit_type'])\n",
    "    df = df[['date', 'latitude', 'longitude', 'area', 'bedrooms', 'pets', 'furnished', 'unit_type']]\n",
    "    \n",
    "    #X_geo = df.to_numpy()\n",
    "    y_geo = model.predict(df)\n",
    "    df['price'] = y_geo\n",
    "\n",
    "    fig = px.scatter_mapbox(df,lon='longitude',lat='latitude',color='price',width=1000,height=800)\n",
    "\n",
    "    #fig = go.Figure(go.Scattermapbox(lon=list(map(str,list(df['longitude']))),lat=list(map(str,list(df['latitude'])))))#,marker=go.scattermapbox.Marker(size=14)))\n",
    "    #go.scattermapbox.Marker(size=14,symbol='square',color=df['price'])\n",
    "    #fig.update_layout(mapbox=dict(accesstoken=mapbox_access_token))\n",
    "                  \n",
    "    # need to fix view and scatter marker size\n",
    "    #fig.data[0].marker = dict(size=10,opacity=0.5,symbol='square')\n",
    "    #fig = px.scatter_mapbox(df,lon='longitude',lat='latitude',color='price')\n",
    "    return fig\n",
    "    \n",
    "fig = map_model(X_test,model)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
