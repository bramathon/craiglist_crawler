{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from lxml import html\n",
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "import numpy as np\n",
    "from functions import *\n",
    "from bs4 import BeautifulSoup\n",
    "import re, requests\n",
    "from neighbourhoods import hoods\n",
    "import pandas as pd\n",
    "import matplotlib.path as mplPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#url = \"http://vancouver.craigslist.ca/search/apa?format=rss&is_paid=all&max_price=2000&min_price=1000&postedToday=1\"\n",
    "url = \"http://vancouver.craigslist.ca/search/apa?format=rss\"\n",
    "apts = feedparser.parse( url )\n",
    "conn = sqlite3.connect('apartments.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_int(string):\n",
    "    return int(re.sub('[^0-9]', '', string))\n",
    "               \n",
    "def get_title(soup):\n",
    "    title= soup.find_all(id='titletextonly')[0]\n",
    "    return title.find(text=True, recursive=False).strip()\n",
    "\n",
    "def get_bedrooms(soup):\n",
    "    soup.select('.housing')[0]\n",
    "    \n",
    "def get_price(soup):\n",
    "    try:\n",
    "        item = soup.select('.price')[0]\n",
    "        price_string = item.find(text=True, recursive=False).strip()\n",
    "        price = int(re.sub('[^0-9]', '', price_string))\n",
    "    except:\n",
    "        price = None\n",
    "    return price\n",
    "\n",
    "def get_location(tree):\n",
    "    try:\n",
    "        longitude = float(tree.xpath('//*[@id=\"map\"]//@data-longitude')[0])\n",
    "        latitude = float(tree.xpath('//*[@id=\"map\"]//@data-latitude')[0])\n",
    "    except:\n",
    "        longitude = None\n",
    "        latitude = None\n",
    "    return [latitude,longitude]\n",
    "\n",
    "def get_address(soup):\n",
    "    try:\n",
    "        address = soup.select('.mapaddress')[0].find(text=True, recursive=False).strip()\n",
    "    except:\n",
    "        address = None\n",
    "    return address\n",
    "\n",
    "def get_location_soup(soup):\n",
    "    # get the location using soup\n",
    "    div = soup.find_all(id=\"map\")[0]\n",
    "    longitude = 0\n",
    "    latitude = 0\n",
    "    return [latitude,longitude]\n",
    "\n",
    "def get_bedrooms(soup):\n",
    "    try:\n",
    "        attr = soup.select('.attrgroup')[0]\n",
    "        bedrooms = None\n",
    "        for s in attr.strings:\n",
    "            if s.find(\"BR\") != -1:\n",
    "                bedrooms = parse_int(s)\n",
    "    except:\n",
    "        bathrooms = None\n",
    "    return bedrooms\n",
    "\n",
    "def get_bathrooms(soup):\n",
    "    try:\n",
    "        attr = soup.select('.attrgroup')[0]\n",
    "        bathrooms = None\n",
    "        for s in attr.strings:\n",
    "            if s.find(\"Ba\") != -1:\n",
    "                text = s.find(\"Ba\")\n",
    "                bathrooms = float(s[:text])\n",
    "    except:\n",
    "        bathrooms = None\n",
    "    return bathrooms\n",
    "\n",
    "def get_area(soup):\n",
    "    try:\n",
    "        attr = soup.select('.attrgroup')[0]\n",
    "        area = None\n",
    "        prev_s = None\n",
    "        for s in attr.strings:\n",
    "            if s.find(\"ft\") != -1:\n",
    "                area = parse_int(prev_s)\n",
    "            prev_s = s\n",
    "    except:\n",
    "        area = None\n",
    "    return area\n",
    "\n",
    "def get_all_the_stuff(soup):\n",
    "    try:\n",
    "        attrs = soup.select('.attrgroup')\n",
    "        stuff = []\n",
    "        for attr in attrs:\n",
    "            for s in attr.strings:\n",
    "                if s.strip() !='':\n",
    "                    stuff.append(s.strip())\n",
    "        stuff = ','.join(stuff)\n",
    "    except:\n",
    "        stuff = None\n",
    "    return stuff\n",
    "\n",
    "def get_date_available(soup):\n",
    "    try:\n",
    "        tag = soup.select(\".housing_movein_now\")[0]\n",
    "        date = tag.attrs['data-date']\n",
    "    except:\n",
    "        date = None\n",
    "    return date\n",
    "\n",
    "def get_neighbourhood(latitude,longitude):\n",
    "    # or, grab small from postig title text\n",
    "    try:\n",
    "        neighbourhood = None\n",
    "        for k,v in hoods.items():\n",
    "            if mplPath.Path(v.as_matrix()).contains_point((longitude,latitude)): # for some reason, files are long,lat\n",
    "                neighbourhood = k\n",
    "                break\n",
    "            if neighbourhood == None:\n",
    "                neighbourhood = re.sub('[()]', '', soup.select('.postingtitletext')[0].small.find(text=True, recursive=False).strip())\n",
    "    except:\n",
    "        neighbourhood = None\n",
    "    return neighbourhood\n",
    "\n",
    "def allie_alert(listing):\n",
    "    # [post_date, post_id, title, latitude, longitude, address, date_available, price, area, neighbourhood,extras,bedrooms,bathrooms]\n",
    "    post_id = listing[1]\n",
    "    title = listing[2]\n",
    "    date_available = listing[6]\n",
    "    price = listing[7]\n",
    "    area = listing[8]\n",
    "    neighbourhood = listing[9]\n",
    "    bedrooms = listing[10]\n",
    "    if date_available == \"2017-09-01\" and price < 2000 and neighbourhood == \n",
    "\n",
    "def send_email(user, pwd, recipient, subject, body):\n",
    "    import smtplib\n",
    "\n",
    "    gmail_user = \"craigslistcrawler604@gmail.com\"\n",
    "    gmail_pwd = \"Calgary1\"\n",
    "    FROM = user\n",
    "    TO = recipient if type(recipient) is list else [recipient]\n",
    "    SUBJECT = subject\n",
    "    TEXT = body\n",
    "\n",
    "    # Prepare actual message\n",
    "    message = \"\"\"\\From: %s\\nTo: %s\\nSubject: %s\\n\\n%s\n",
    "    \"\"\" % (FROM, \", \".join(TO), SUBJECT, TEXT)\n",
    "    try:\n",
    "        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "        server.ehlo()\n",
    "        server.starttls()\n",
    "        server.login(gmail_user, gmail_pwd)\n",
    "        server.sendmail(FROM, TO, message)\n",
    "        server.close()\n",
    "        print('successfully sent the mail')\n",
    "    except:\n",
    "        print(\"failed to send mail\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (4>5 or 3>2) and 1 > 2:\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://vancouver.craigslist.ca/rds/apa/6214151870.html'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry = apts.entries[0]\n",
    "page = requests.get(entry.link)\n",
    "tree = html.fromstring(page.content)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "entry.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for entry in reversed(apts.entries):\n",
    "    # Grab some in info from the entry\n",
    "    post_date = entry.updated\n",
    "    post_id = entry.id\n",
    "    title = entry.title\n",
    "    print(post_date)\n",
    "    print(post_id)\n",
    "    # check if the entry is already in the database\n",
    "    c.execute('SELECT * FROM apartments WHERE id = ? AND date = ?', [post_id,post_date])\n",
    "    if c.fetchone():\n",
    "        print(\"Already in db...\")\n",
    "    else:\n",
    "        # Go get the page\n",
    "        page = requests.get(entry.link)\n",
    "        tree = html.fromstring(page.content)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        latitude,longitude = get_location(tree)\n",
    "        \n",
    "        #if latitude == None or longitude == None:\n",
    "            #print(\"No lat-long, moving to next entry\")\n",
    "            #continue\n",
    "        \n",
    "        address = get_address(soup)\n",
    "        price = get_price(soup)\n",
    "        area = get_area(soup)\n",
    "        bedrooms = get_bedrooms(soup)\n",
    "        bathrooms = get_bathrooms(soup)\n",
    "        extras = get_all_the_stuff(soup)\n",
    "        date_available = get_date_available(soup)\n",
    "        neighbourhood = get_neighbourhood(latitude,longitude)\n",
    "        print(\"Date available: %s\" % date_available)\n",
    "        listing = [post_date, post_id, title, latitude, longitude, address, date_available, price, area, neighbourhood,extras,bedrooms,bathrooms]\n",
    "        allie_alert(listing)\n",
    "        c.execute('INSERT INTO apartments VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)', [post_date, post_id, title, latitude, longitude, address, date_available, price, area, neighbourhood,extras,bedrooms,bathrooms])\n",
    "        conn.commit()\n",
    "        print(\"Added entry %s to db\" % post_id)\n",
    "    time.sleep(5)\n",
    "\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
